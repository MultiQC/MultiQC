
import numpy as np
from collections import OrderedDict
# given supported python versions see if we still need
# OrderedDict or could rely on dict

_SEP = '\t'
_KEY_SEP = '/'

# some good-looking presets for pair-type report section
# consider moving to separate yml file
pairtypes_common = OrderedDict()
pairtypes_common['UU'] = '#33a02c' # Green
pairtypes_common['uu'] = '#b2df8a' # Pale green (walks-policy all)
pairtypes_common['RU'] = '#b2df8a' # Pale green (walks-policy mask)
pairtypes_common['UR'] = '#a6cee3' # Pale blue (walks-policy mask)
pairtypes_common['WW'] = '#1f78b4' # Blue
pairtypes_common['DD'] = '#fff900' # Yellow
pairtypes_common['MU'] = '#ff7f00' # Orange
pairtypes_common['MR'] = '#fdbf6f' # Pale orange (walks-policy mask)
pairtypes_common['mu'] = '#fdbf6f' # Pale orange (walks-policy all)
pairtypes_common['MM'] = '#e31a1c' # Red
pairtypes_common['mm'] = '#fb9a99' # Pale red (walks-policy all)
pairtypes_common['NM'] = '#b15928' # Brown
pairtypes_common['nm'] = '#ffff99' # Pale brown (yellow-ish) (walks-policy all)
pairtypes_common['NU'] = '#6a3d9a' # Violet
pairtypes_common['NR'] = '#cab2d6' # Pale violet (walks-policy mask)
pairtypes_common['nu'] = '#cab2d6' # Pale violet (walks-policy all)
pairtypes_common['NN'] = '#9e0090' # Magenta
pairtypes_common['nn'] = '#ff7ff3' # Pale magenta (walks-policy all)
pairtypes_common['XX'] = '#000000'

# add color to sorted keys:
cis_range_colors = [
    '#8c2d04',  # short-range cis
    '#cc4c02',
    '#ec7014',
    '#fe9929',
    '#fec44f',
    '#fee391',
    '#ffffd4',  #long-range cis
    ]

# this should be based on chromosome sizes, not an arbitrary number
def contact_areas(distbins, scaffold_length):
    """
    calculate possible number of pairwise contacts for a given
    range of genomic distances given some scaffold length

    Paramteres
    ----------
    distbins : ndarray
        an array of genomic distances
    scaffold_length: float
        length of a scaffold (should be chromsizes)
    """
    distbins = distbins.astype(float)
    scaffold_length = float(scaffold_length)
    outer_areas = np.maximum(scaffold_length - distbins[:-1], 0) ** 2
    inner_areas = np.maximum(scaffold_length - distbins[1:], 0) ** 2
    return 0.5 * (outer_areas - inner_areas)

class ParseError(Exception):
    pass

def read_pairs_stats(file_handle):
    """
    parse .stats file generated by pairtools into a dictionary.
    Pairtools-generated .stats file are yaml/json-like, but
    historically they have adopted a custom syntax using "/" to
    separate hierarchical keys of nested dictionaries.

    This function will attempt to parse .stats file, filling out
    output dictionary stat_from_file.
    It will raise ParseError if .stats is not compliant.

    Parameters
    ----------
    file_handle: .stats file handle

    Returns
    -------
    stat_from_file : OrderedDict
        dictionary with stats valued parsed from .stats
    """
    # fill in from file - file_handle:
    stat_from_file = OrderedDict()
    #
    min_log10_dist=0
    max_log10_dist=9
    log10_dist_bin_step=0.25
    # some variables used for initialization:
    # genomic distance bining for the ++/--/-+/+- distribution
    _dist_bins = (np.r_[0,
        np.round(10**np.arange(min_log10_dist, max_log10_dist+0.001,
                               log10_dist_bin_step))
        .astype(np.int)]
    )

    # common error message for ParseError
    invalid_file_msg = f"{file_handle.name} is not a valid stats file: "

    # establish structure of an empty _stat:
    stat_from_file['total'] = 0
    stat_from_file['total_unmapped'] = 0
    stat_from_file['total_single_sided_mapped'] = 0
    # total_mapped = total_dups + total_nodups
    stat_from_file['total_mapped'] = 0
    stat_from_file['total_dups'] = 0
    stat_from_file['total_nodups'] = 0
    ########################################
    # the rest of stats are based on nodups:
    ########################################
    stat_from_file['cis'] = 0
    stat_from_file['trans'] = 0
    stat_from_file['pair_types'] = {}
    # to be removed:
    stat_from_file['dedup'] = {}

    # we probably do not need to define these here,
    # just read the 1-key entries and then parse those out:
    stat_from_file['cis_1kb+'] = 0
    stat_from_file['cis_2kb+'] = 0
    stat_from_file['cis_4kb+'] = 0
    stat_from_file['cis_10kb+'] = 0
    stat_from_file['cis_20kb+'] = 0
    stat_from_file['cis_40kb+'] = 0

    stat_from_file['chrom_freq'] = OrderedDict()

    stat_from_file['dist_freq'] = OrderedDict([
        ('+-', np.zeros(len(_dist_bins), dtype=np.int)),
        ('-+', np.zeros(len(_dist_bins), dtype=np.int)),
        ('--', np.zeros(len(_dist_bins), dtype=np.int)),
        ('++', np.zeros(len(_dist_bins), dtype=np.int)),
        ])

    # pack distance bins along with dist_freq at least for now
    stat_from_file['dist_bins'] = _dist_bins

    # line by line parsing
    for l in file_handle:
        fields = l.strip().split(_SEP)
        if len(fields) == 0:
            # skip empty lines:
            continue
        if len(fields) != 2:
            # expect two _SEP separated values per line:
            raise ParseError(
                '{} is not a valid stats file'.format(file_handle.name))
        # extract key and value, then split the key:
        putative_key, putative_val =  fields[0], fields[1]
        key_fields = putative_key.split(_KEY_SEP)
        # we should impose a rigid structure of .stats or redo it:
        if len(key_fields)==1:
            key = key_fields[0]
            if key in stat_from_file:
                stat_from_file[key] = int(fields[1])
            else:
                raise ParseError(f'{invalid_file_msg}unknown field {key} detected')
        else:
            # in this case key must be in ['pair_types','chrom_freq','dist_freq','dedup']
            # get the first 'key' and keep the remainders in 'key_fields'
            key = key_fields.pop(0)
            if key in ['pair_types', 'dedup']:
                # assert there is only one element in key_fields left:
                # 'pair_types' and 'dedup' treated the same
                if len(key_fields) == 1:
                    stat_from_file[key][key_fields[0]] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 1 identifier')
            elif key == 'chrom_freq':
                # assert remaining key_fields == [chr1, chr2]:
                if len(key_fields) == 2:
                    stat_from_file[key][tuple(key_fields)] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 2 identifiers')
            elif key == 'dist_freq':
                # assert that last element of key_fields is the 'directions'
                if len(key_fields) == 2:
                    # assert 'dirs' in ['++','--','+-','-+']
                    dirs = key_fields.pop()
                    # there is only genomic distance range of the bin that's left:
                    bin_range, = key_fields
                    # extract left border of the bin "1000000+" or "1500-6000":
                    if bin_range.endswith('+'):
                        dist_bin_left = bin_range.strip('+')
                    else:
                        dist_bin_left = bin_range.split('-')[0]
                    # get the index of that bin:
                    bin_idx = np.searchsorted(_dist_bins, int(dist_bin_left), 'right') - 1
                    # store corresponding value:
                    stat_from_file[key][dirs][bin_idx] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 2 identifiers')
            else:
                raise ParseError(f'{invalid_file_msg}unknown field {key} detected')
    # add some fractions:
    stat_from_file['frac_unmapped'] = stat_from_file['total_unmapped']/stat_from_file['total']*100.
    stat_from_file['frac_single_sided_mapped'] = stat_from_file['total_single_sided_mapped']/stat_from_file['total']*100.
    # total_mapped = total_dups + total_nodups
    # should the following be divided by mapped or by total ?!
    stat_from_file['frac_mapped'] = stat_from_file['total_mapped']/stat_from_file['total']*100.
    stat_from_file['frac_dups'] = stat_from_file['total_dups']/stat_from_file['total']*100.
    ########################################
    # the rest of stats are based on nodups:
    ########################################
    stat_from_file['cis_percent'] = stat_from_file['cis']/stat_from_file['total_nodups']*100.

    return stat_from_file

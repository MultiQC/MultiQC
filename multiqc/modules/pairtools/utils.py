import numpy as np
from collections import OrderedDict
# given supported python versions see if we still need
# OrderedDict or could rely on dict

_SEP = '\t'
_KEY_SEP = '/'


def genomic_dist_human_str(dist_in_bp):
    """
    turn genomic distance (in basepairs) into
    human readable string (supports Mb, Kb and bp)
    """
    if dist_in_bp:
        _bp = int(dist_in_bp)
        if _bp // 1_000_000:
            return f"{_bp // 1_000_000}Mb"
        elif _bp // 1_000:
            return f"{_bp // 1_000}Kb"
        else:
            return f"{_bp}"
    else:
        return ""


def edges_to_intervals(edges):
    """
    turn an array of internal edges into an array of
    intervals, i.e.:
    [1,2,3] -> [(0,1),(1,2),(2,3),(3,None)]
    """
    _edges = np.r_[0, edges, None]
    zippend_edges = zip(_edges[:-1], _edges[1:])
    return list(zippend_edges)


def cumsums_to_rangesums(cumsums, total):
    """
    transform cumulative counts to counts in the intervals
    using the total counts information, e.g.:
    [a1,... aN] ->
    [total, a1,... aN, 0] ->
    [total-a1, a1-a2, ... aN-0]
    """
    _cumcsums = np.r_[total, cumsums, 0]
    return list(_cumcsums[:-1] - _cumcsums[1:])


# this should be based on chromosome sizes, not an arbitrary number
def contact_areas(distbins, scaffold_length):
    """
    calculate possible number of pairwise contacts for a given
    range of genomic distances given some scaffold length

    Paramteres
    ----------
    distbins : ndarray
        an array of genomic distances
    scaffold_length: float
        length of a scaffold (should be chromsizes)
    """
    distbins = distbins.astype(float)
    scaffold_length = float(scaffold_length)
    outer_areas = np.maximum(scaffold_length - distbins[:-1], 0) ** 2
    inner_areas = np.maximum(scaffold_length - distbins[1:], 0) ** 2
    return 0.5 * (outer_areas - inner_areas)

class ParseError(Exception):
    pass

def read_stats_from_file(file_handle):
    """
    parse .stats file generated by pairtools into a dictionary.
    Pairtools-generated .stats file are yaml/json-like, but
    historically they have adopted a custom syntax using "/" to
    separate hierarchical keys of nested dictionaries.

    This function will attempt to parse .stats file, filling out
    output dictionary stat_from_file.
    It will raise ParseError if .stats is not compliant.

    Parameters
    ----------
    file_handle: .stats file handle

    Returns
    -------
    stat_from_file : OrderedDict
        dictionary with stats valued parsed from .stats
    """
    # fill in from file - file_handle:
    stat_from_file = OrderedDict()
    #
    min_log10_dist=0
    max_log10_dist=9
    log10_dist_bin_step=0.25
    # some variables used for initialization:
    # genomic distance bining for the ++/--/-+/+- distribution
    _dist_bins = (np.r_[0,
        np.round(10**np.arange(min_log10_dist, max_log10_dist+0.001,
                               log10_dist_bin_step))
        .astype(np.int)]
    )

    # common error message for ParseError
    invalid_file_msg = f"{file_handle.name} is not a valid stats file: "

    # establish structure of an empty _stat:
    stat_from_file['total'] = 0
    stat_from_file['total_unmapped'] = 0
    stat_from_file['total_single_sided_mapped'] = 0
    # total_mapped = total_dups + total_nodups
    stat_from_file['total_mapped'] = 0
    stat_from_file['total_dups'] = 0
    stat_from_file['total_nodups'] = 0
    ########################################
    # the rest of stats are based on nodups:
    ########################################
    stat_from_file['cis'] = 0
    stat_from_file['trans'] = 0
    stat_from_file['pair_types'] = {}
    # to be removed:
    stat_from_file['dedup'] = {}

    # start using chromsizes
    stat_from_file['chromsizes'] = {}

    # don't need to defined them here - but right now
    # this definitions help us define the structure of
    # the stats file:
    stat_from_file['cis_1kb+'] = 0
    stat_from_file['cis_2kb+'] = 0
    stat_from_file['cis_4kb+'] = 0
    stat_from_file['cis_10kb+'] = 0
    stat_from_file['cis_20kb+'] = 0
    stat_from_file['cis_40kb+'] = 0

    stat_from_file['chrom_freq'] = OrderedDict()

    stat_from_file['dist_freq'] = OrderedDict([
        ('+-', np.zeros(len(_dist_bins), dtype=np.int)),
        ('-+', np.zeros(len(_dist_bins), dtype=np.int)),
        ('--', np.zeros(len(_dist_bins), dtype=np.int)),
        ('++', np.zeros(len(_dist_bins), dtype=np.int)),
        ])

    # pack distance bins along with dist_freq at least for now
    stat_from_file['dist_bins'] = _dist_bins

    # line by line parsing
    for l in file_handle:
        fields = l.strip().split(_SEP)
        if len(fields) == 0:
            # skip empty lines:
            continue
        if len(fields) != 2:
            # expect two _SEP separated values per line:
            raise ParseError(
                '{} is not a valid stats file'.format(file_handle.name))
        # extract key and value, then split the key:
        putative_key, putative_val =  fields[0], fields[1]
        key_fields = putative_key.split(_KEY_SEP)
        # we should impose a rigid structure of .stats or redo it:
        if len(key_fields)==1:
            key = key_fields[0]
            if key in stat_from_file:
                stat_from_file[key] = int(fields[1])
            else:
                raise ParseError(f'{invalid_file_msg}unknown field {key} detected')
        else:
            # in this case key must be in ['pair_types','chrom_freq','dist_freq','dedup']
            # get the first 'key' and keep the remainders in 'key_fields'
            key = key_fields.pop(0)
            if key in ['pair_types', 'dedup']:
                # assert there is only one element in key_fields left:
                # 'pair_types' and 'dedup' treated the same
                if len(key_fields) == 1:
                    stat_from_file[key][key_fields[0]] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 1 identifier')
            elif key == 'chrom_freq':
                # assert remaining key_fields == [chr1, chr2]:
                if len(key_fields) == 2:
                    stat_from_file[key][tuple(key_fields)] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 2 identifiers')
            elif key == 'dist_freq':
                # assert that last element of key_fields is the 'directions'
                if len(key_fields) == 2:
                    # assert 'dirs' in ['++','--','+-','-+']
                    dirs = key_fields.pop()
                    # there is only genomic distance range of the bin that's left:
                    bin_range, = key_fields
                    # extract left border of the bin "1000000+" or "1500-6000":
                    if bin_range.endswith('+'):
                        dist_bin_left = bin_range.strip('+')
                    else:
                        dist_bin_left = bin_range.split('-')[0]
                    # get the index of that bin:
                    bin_idx = np.searchsorted(_dist_bins, int(dist_bin_left), 'right') - 1
                    # store corresponding value:
                    stat_from_file[key][dirs][bin_idx] = int(fields[1])
                else:
                    raise ParseError(f'{invalid_file_msg}{key} section implies 2 identifiers')
            else:
                raise ParseError(f'{invalid_file_msg}unknown field {key} detected')
    # add some fractions:
    stat_from_file['frac_unmapped'] = stat_from_file['total_unmapped']/stat_from_file['total']*100.
    stat_from_file['frac_single_sided_mapped'] = stat_from_file['total_single_sided_mapped']/stat_from_file['total']*100.
    # total_mapped = total_dups + total_nodups
    # should the following be divided by mapped or by total ?!
    stat_from_file['frac_mapped'] = stat_from_file['total_mapped']/stat_from_file['total']*100.
    stat_from_file['frac_dups'] = stat_from_file['total_dups']/stat_from_file['total']*100.
    ########################################
    # the rest of stats are based on nodups:
    ########################################
    stat_from_file['cis_percent'] = stat_from_file['cis']/stat_from_file['total_nodups']*100.

    return stat_from_file

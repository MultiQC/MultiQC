""" MultiQC module to parse output from the Seqera Platform CLI """

import json
import logging
import os
import tarfile
from collections import defaultdict

from multiqc.modules.base_module import BaseMultiqcModule, ModuleNoSamplesFound
from multiqc.plots import bargraph

log = logging.getLogger(__name__)


def _read_json_from_tar_gz(tar_file, fname):
    try:
        fh = tar_file.extractfile(tar_file.getmember(fname))
        contents = fh.read()
    except:
        log.warning(f"Could not extract file {fname} from archive {tar_file}")
        return {}
    try:
        data = json.loads(contents)
    except:
        log.warning(f"Could parse JSON from {fname} in {tar_file}")
        return {}
    return data


def _parse_workflow_json(data):
    return {k: data.get(k) for k in ["repository", "start", "complete", "revision"]}


def _parse_workflow_load_json(data):
    return {
        k: data.get(k)
        for k in [
            "cpuEfficiency",
            "memoryEfficiency",
            "cpuTime",
            "readBytes",
            "writeBytes",
            "cost",
            "pending",
            "submitted",
            "running",
            "succeeded",
            "failed",
            "cached",
        ]
    }


class MultiqcModule(BaseMultiqcModule):
    """
    Seqera Platform CLI module for MultiQC. Should be able to process logs dump
    usually written in a form of a tar-gz archive, as well as its uncompressed version.
    that is reading workflow.json and workflow-load.json files directly.
    """

    def __init__(self):
        super(MultiqcModule, self).__init__(
            name="Seqera Platform CLI",
            anchor="seqera_cli",
            href="https://github.com/seqeralabs/tower-cli",
            info="reports statistics generated by the Seqera Platform CLI.",
            doi="10.1016/j.ajhg.2017.01.017",
        )

        data_by_run = defaultdict(dict)

        # Parsing the tar-gz dump
        for f in self.find_log_files("seqera_cli/run_dump", filecontents=False):
            with tarfile.open(os.path.join(f["root"], f["fn"])) as tar_file:
                if "workflow.json" not in tar_file.getnames():
                    continue
                d = _read_json_from_tar_gz(tar_file, "workflow.json")
                run_id = d.get("id")
                if not run_id:
                    continue
                d = _parse_workflow_json(d)
                if not d:
                    continue
                self.add_data_source(f)
                self.add_software_version(d.get("revision"))
                data_by_run[run_id].update(d)

                # Check if also workflow-load.json sits next to workflow.json
                if "workflow-load.json" in tar_file.getnames():
                    d = _read_json_from_tar_gz(tar_file, "workflow-load.json")
                    data_by_run[run_id].update(_parse_workflow_load_json(d))

        # Parsing the json files directly
        for f in self.find_log_files("seqera_cli/workflow"):
            d = json.loads(f["f"])
            run_id = d.get("id")
            if not run_id:
                continue
            d = _parse_workflow_json(d)
            if not d:
                continue
            self.add_data_source(f)
            self.add_software_version(d.get("revision"))
            data_by_run[run_id].update(d)

            # Check if also workflow-load.json sits next to workflow.json
            workflow_load_path = os.path.join(f["root"], "workflow-load.json")
            if os.path.isfile(workflow_load_path):
                with open(workflow_load_path) as fh:
                    d = json.load(fh)
                    data_by_run[run_id].update(_parse_workflow_load_json(d))

        # Filter to strip out ignored sample names
        data_by_run = self.ignore_samples(data_by_run)

        if len(data_by_run) == 0:
            raise ModuleNoSamplesFound

        log.info("Found {} reports".format(len(data_by_run)))

        # Write parsed report data to a file
        self.write_data_file(data_by_run, "multiqc_seqera_cli")

        headers = {
            "repository": {
                "title": "Repository",
                "description": "Name of the repository",
                "scale": False,
                "modify": lambda x: f'<a href="{x}">{x}</a>',
            },
            "start": {
                "title": "Start",
                "description": "Start time of the workflow",
                "scale": False,
            },
            "complete": {
                "title": "Complete",
                "description": "End time of the workflow",
                "scale": False,
            },
            "cpuEfficiency": {
                "title": "CPU Efficiency",
                "description": "Percentage of CPU time used by the workflow",
                "format": "{:,.2f}",
                "scale": "RdYlGn",
            },
            "memoryEfficiency": {
                "title": "Memory Efficiency",
                "description": "Percentage of memory used by the workflow",
                "format": "{:,.2f}",
                "scale": "RdYlGn",
            },
            "cpuTime": {
                "title": "CPU Time",
                "description": "Total CPU time used by the workflow",
                "format": "{:,.2f}",
                "scale": "Greys",
                "suffix": "&nbsp;h",
                "modify": lambda x: x / 1000 / 3600,
            },
            "readBytes": {
                "title": "Read GB",
                "description": "Total gigabytes read by the workflow",
                "format": "{:,.2f}",
                "scale": "Blues",
                "suffix": "&nbsp;GB",
                "modify": lambda x: x / 1024 / 1024 / 1024,
            },
            "writeBytes": {
                "title": "Write GB",
                "description": "Total gigabytes written by the workflow",
                "format": "{:,.2f}",
                "scale": "Greens",
                "suffix": "&nbsp;GB",
                "modify": lambda x: x / 1024 / 1024 / 1024,
            },
            "cost": {
                "title": "Cost",
                "description": "Cost of the workflow",
                "format": "{:,.2f}",
                "scale": "Reds",
            },
        }
        self.general_stats_addcols(data_by_run, headers)

        pconfig = {
            "id": "seqera_cli_process_status",
            "title": "Seqera Platform CLI: processes statuses",
        }
        keys = [
            "pending",
            "submitted",
            "running",
            "succeeded",
            "failed",
            "cached",
        ]
        self.add_section(
            name="Seqera Platform CLI",
            anchor="seqera-platform-cli",
            plot=bargraph.plot(data_by_run, keys, pconfig),
        )

""" MultiQC module to parse output from the Seqera Platform CLI """

import datetime
import json
import logging
import os
import tarfile
from collections import defaultdict

from multiqc.modules.base_module import BaseMultiqcModule, ModuleNoSamplesFound
from multiqc.plots import bargraph

log = logging.getLogger(__name__)


def _read_json_from_tar_gz(tar_file, fname):
    try:
        fh = tar_file.extractfile(tar_file.getmember(fname))
        contents = fh.read()
    except Exception as e:
        log.warning(f"Could not extract file {fname} from archive {tar_file}: {e}")
        return {}
    try:
        data = json.loads(contents)
    except Exception as e:
        log.warning(f"Could parse JSON from {fname} in {tar_file}: {e}")
        return {}
    return data


def _parse_workflow_json(data):
    keys = ["repository", "start", "complete", "revision"]
    data = {k: data.get(k) for k in keys}
    # "start" and "complete" are time stamps like time stamps like 2023-10-22T14:39:01Z
    # parse them with a library, take the difference "complete" - "start" to get the
    # duration, and convert the duration it to a human-readable format.
    if "start" in data and "complete" in data:
        start = datetime.datetime.strptime(data["start"], "%Y-%m-%dT%H:%M:%SZ")
        complete = datetime.datetime.strptime(data["complete"], "%Y-%m-%dT%H:%M:%SZ")
        data["duration"] = complete - start
    return data


def _parse_workflow_load_json(data):
    keys = [
        "cpuEfficiency",
        "memoryEfficiency",
        "cpuTime",
        "readBytes",
        "writeBytes",
        "cost",
        "pending",
        "submitted",
        "running",
        "succeeded",
        "failed",
        "cached",
    ]
    data = {k: data.get(k) for k in keys}
    return data


class MultiqcModule(BaseMultiqcModule):
    """
    Seqera Platform CLI module for MultiQC. Should be able to process logs dump
    usually written in a form of a tar-gz archive, as well as its uncompressed version.
    that is reading workflow.json and workflow-load.json files directly.
    """

    def __init__(self):
        super(MultiqcModule, self).__init__(
            name="Seqera Platform CLI",
            anchor="seqera_cli",
            href="https://github.com/seqeralabs/tower-cli",
            info="reports statistics generated by the Seqera Platform CLI.",
            # doi="",  # No DOI for this tool
        )

        data_by_run = defaultdict(dict)

        # Parsing the tar-gz dump
        for f in self.find_log_files("seqera_cli/run_dump", filecontents=False):
            with tarfile.open(os.path.join(f["root"], f["fn"])) as tar_file:
                if "workflow.json" not in tar_file.getnames():
                    continue
                d = _read_json_from_tar_gz(tar_file, "workflow.json")
                run_id = d.get("id")
                if not run_id:
                    continue
                d = _parse_workflow_json(d)
                if not d:
                    continue
                self.add_data_source(f)
                self.add_software_version(d.get("revision"))
                data_by_run[run_id].update(d)

                # Check if also workflow-load.json sits next to workflow.json
                if "workflow-load.json" in tar_file.getnames():
                    d = _read_json_from_tar_gz(tar_file, "workflow-load.json")
                    data_by_run[run_id].update(_parse_workflow_load_json(d))

        # Parsing the json files directly
        for f in self.find_log_files("seqera_cli/workflow"):
            d = json.loads(f["f"])
            run_id = d.get("id")
            if not run_id:
                continue
            d = _parse_workflow_json(d)
            if not d:
                continue
            self.add_data_source(f)
            self.add_software_version(d.get("revision"))
            data_by_run[run_id].update(d)

            # Check if also workflow-load.json sits next to workflow.json
            workflow_load_path = os.path.join(f["root"], "workflow-load.json")
            if os.path.isfile(workflow_load_path):
                with open(workflow_load_path) as fh:
                    d = json.load(fh)
                    data_by_run[run_id].update(_parse_workflow_load_json(d))

        # Filter to strip out ignored sample names
        data_by_run = self.ignore_samples(data_by_run)

        if len(data_by_run) == 0:
            raise ModuleNoSamplesFound
        log.info(f"Found {len(data_by_run)} reports")

        # Write parsed report data to a file
        self.write_data_file(data_by_run, "multiqc_seqera_cli")

        headers = {
            "repository": {
                "title": "Repository",
                "description": "Name of the repository",
                "scale": False,
                "modify": lambda x: f'<a href="{x}">{x.replace("https://", "").replace("http://", "").replace("github.com/", "")}</a>',
            },
            "start": {
                "title": "Start",
                "description": "Start time of the workflow",
                "scale": False,
                "hidden": True,
            },
            "complete": {
                "title": "Complete",
                "description": "End time of the workflow",
                "scale": False,
                "hidden": True,
            },
            "duration": {
                "title": "Duration",
                "description": "Duration of the workflow",
                "scale": "BuPu",
                "to_float": lambda x: x.total_seconds(),
            },
            "cpuEfficiency": {
                "title": "CPU Efficiency",
                "description": "Percentage of CPU time used by the workflow",
                "format": "{:,.2f}",
                "suffix": "%",
                "max": 100,
                "scale": "RdYlGn",
            },
            "memoryEfficiency": {
                "title": "Memory Efficiency",
                "description": "Percentage of memory used by the workflow",
                "format": "{:,.2f}",
                "suffix": "%",
                "max": 100, 
                "scale": "YlGn",
            },
            "cpuTime": {
                "title": "CPU Time",
                "description": "Total CPU time used by the workflow",
                "format": "{:,.2f}",
                "scale": "Greys",
                "suffix": "&nbsp;h",
                "modify": lambda x: x / 1000 / 3600,
            },
            "readBytes": {
                "title": "Read GB",
                "description": "Total gigabytes read by the workflow",
                "format": "{:,.2f}",
                "scale": "Blues",
                "suffix": "&nbsp;GB",
                "modify": lambda x: x / 1024 / 1024 / 1024,
            },
            "writeBytes": {
                "title": "Write GB",
                "description": "Total gigabytes written by the workflow",
                "format": "{:,.2f}",
                "scale": "Greens",
                "suffix": "&nbsp;GB",
                "modify": lambda x: x / 1024 / 1024 / 1024,
            },
            "cost": {
                "title": "Cost",
                "description": "Cost of the workflow",
                "format": "{:,.2f}",
                "scale": "Reds",
            },
        }
        self.general_stats_addcols(data_by_run, headers)

        pconfig = {
            "id": "seqera_cli_process_status",
            "title": "Seqera Platform CLI: processes statuses",
        }
        cats = {
            "pending": {"name": "Pending", "color": "#8f4199"},
            "submitted": {"name": "Submitted", "color": "#e68642"},
            "running": {"name": "Running", "color": "#4256e7"},
            "cached": {"name": "Cached", "color": "#939598"},
            "succeeded": {"name": "Succeeded", "color": "#28ae61"},
            "failed": {"name": "Failed", "color": "#e7363e"},
        }
        self.add_section(
            name="Seqera Platform CLI",
            anchor="seqera-platform-cli",
            plot=bargraph.plot(data_by_run, cats, pconfig),
        )
